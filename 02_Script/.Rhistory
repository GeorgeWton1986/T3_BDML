mutate(p_missing= n_missing/nobs_train) %>%
filter(n_missing!= 0) %>%
arrange(-n_missing)
train_aptos_miss
# Visualizar variables con missing values
## Gráfico para surface_total (área total)
graf_ms1 <- ggplot(train_aptos, aes(surface_total)) +
geom_histogram(color = "#000000", fill = "#0099F8") +
geom_vline(xintercept = median(train_aptos$surface_total, na.rm = TRUE), linetype = "dashed", color = "red") +
geom_vline(xintercept = mean(train_aptos$surface_total, na.rm = TRUE), linetype = "dashed", color = "blue") +
ggtitle("GRÁFICA 1 - Área total") +
theme_bw() +
theme(plot.title = element_text(size = 18))
ggsave("../04_Views/GRAFICO1-HISTOGRAMA-AREATOTAL.png", plot = graf_ms1, dpi = 150, width = 8, height = 6)
## Gráfico para surface_covered (área privada)
graf_ms2 <- ggplot(train_aptos, aes(surface_covered)) +
geom_histogram(color = "#000000", fill = "#0099F8") +
geom_vline(xintercept = median(train_aptos$surface_covered, na.rm = TRUE), linetype = "dashed", color = "red") +
geom_vline(xintercept = mean(train_aptos$surface_covered, na.rm = TRUE), linetype = "dashed", color = "blue") +
ggtitle("GRÁFICA 2 - Área privada") +
theme_bw() +
theme(plot.title = element_text(size = 18))
ggsave("../04_Views/GRAFICO2-HISTOGRAMA-AREAPRIVADA.png", plot = graf_ms2, dpi = 150, width = 8, height = 6)
## Gráfico para rooms (habitaciones)
graf_ms3 <- ggplot(train_aptos, aes(rooms)) +
geom_histogram(color = "#000000", fill = "#0099F8") +
geom_vline(xintercept = median(train_aptos$rooms, na.rm = TRUE), linetype = "dashed", color = "red") +
geom_vline(xintercept = mean(train_aptos$rooms, na.rm = TRUE), linetype = "dashed", color = "blue") +
ggtitle("GRÁFICA 3 -Habitaciones") +
theme_bw() +
theme(plot.title = element_text(size = 18))
ggsave("../04_Views/GRAFICO3-HISTOGRAMA-HABITACIONES.png", plot = graf_ms3, dpi = 150, width = 8, height = 6)
## Gráfico para bathrooms (baños)
graf_ms4 <- ggplot(train_aptos, aes(bathrooms)) +
geom_histogram(color = "#000000", fill = "#0099F8") +
geom_vline(xintercept = median(train_aptos$bathrooms, na.rm = TRUE), linetype = "dashed", color = "red") +
geom_vline(xintercept = mean(train_aptos$bathrooms, na.rm = TRUE), linetype = "dashed", color = "blue") +
ggtitle("GRÁFICA 4 - Baños") +
theme_bw() +
theme(plot.title = element_text(size = 18))
ggsave("../04_Views/GRAFICO4-HISTOGRAMA-BAÑOS.png", plot = graf_ms4, dpi = 150, width = 8, height = 6)
# Imputación de variables con la mediana y moda
## 1. Variable surface_total con mediana
mediana_surface_total <- median(train_aptos$surface_total, na.rm = TRUE)
train_aptos <- train_aptos  %>%
mutate(surface_total = ifelse(is.na(surface_total) == TRUE, mediana_surface_total, surface_total))
## 2. Variable surface_covered con mediana
mediana_surface_covered <- median(train_aptos$surface_covered, na.rm = TRUE)
train_aptos <- train_aptos  %>%
mutate(surface_covered = ifelse(is.na(surface_covered) == TRUE, mediana_surface_covered, surface_covered))
## 3.  Variable rooms con la moda
moda_rooms <- train_aptos %>%
filter(!is.na(rooms)) %>%
count(rooms) %>%
arrange(desc(n)) %>%
slice(1) %>%
pull(rooms)
train_aptos <- train_aptos  %>%
mutate(rooms = ifelse(is.na(rooms) == TRUE, moda_rooms, rooms))
## 4.Variable bathrooms con la moda
moda_bathrooms <- train_aptos %>%
filter(!is.na(bathrooms)) %>%
count(bathrooms) %>%
arrange(desc(n)) %>%
slice(1) %>%
pull(bathrooms)
train_aptos <- train_aptos  %>%
mutate(bathrooms = ifelse(is.na(bathrooms) == TRUE, moda_bathrooms, bathrooms))
# Validación de correcta imputación de missing values en variables numéricas
skim(train_aptos)
train_aptos <- as.data.frame(train_aptos)
stargazer(train_aptos, type = "text")
# Calcular el precio por metro cuadrado
train_aptos <- train_aptos %>%
mutate(precio_mt2 = round(price / surface_total, 0))
skim(train_aptos)
# Histograma del precio por metro cuadrado
graf_5 <- ggplot(train_aptos, aes(precio_mt2)) +
geom_histogram(color = "#000000", fill = "#0099F8") +
ggtitle("GRÁFICA 4 - Precio por metro cuadrado (millones)") +
scale_x_continuous(labels = function(x) x / 1e6) +
theme_bw() +
theme(plot.title = element_text(size = 18))
ggsave("../04_Views/GRAFICO5-HISTOGRAMA-PRECIOXMETROCUADRADO.png", plot = graf_5, dpi = 150, width = 8, height = 6)
# Box plot del precio por metro cuadrado
graf_6 <- train_aptos %>%
ggplot(aes(y = precio_mt2)) +
geom_boxplot(fill = "darkblue", alpha = 0.4) +
labs(
title = "Muestra completa",
y = "Precio por metro cuadrado (millones)", x = "") +
scale_y_continuous(labels = function(x) x / 1e6) +
theme_bw()
ggsave("../04_Views/GRAFICO6-BOXPLOT-PRECIOXMETROCUADRADO.png", plot = graf_6, dpi = 150, width = 8, height = 6)
# Ante outliers superiores se aplica la Metodología de percentil 99%
#p1 <- quantile(train_aptos$precio_mt2, probs = 0.01, na.rm = TRUE)
p99 <- quantile(train_aptos$precio_mt2, probs = 0.99, na.rm = TRUE)
train_aptos <- train_aptos %>%
filter(precio_mt2 <= p99)
# Filtrar solo los valores menores o iguales al límite superior
graf_7 <- train_aptos %>%
ggplot(aes(y = precio_mt2)) +
geom_boxplot(fill = "darkblue", alpha = 0.4) +
labs(
title = "Muestra filtrada - P99",
y = "Precio por metro cuadrado (millones)", x = "") +
scale_y_continuous(labels = function(x) x / 1e6) +
theme_bw()
ggsave("../04_Views/GRAFICO6-BOXPLOT-PRECIOXMETROCUADRADO-P99.png", plot = graf_7, dpi = 150, width = 8, height = 6)
# Observamos la primera visualización de la ubicación de los inmubles de la base train_aptos
leaflet() %>%
addTiles() %>%
addCircles(lng = train_aptos$lon,
lat = train_aptos$lat)
# Ahora solo nos quedaremos con las observaciones que efectivamente están dentro de Chapinero y no están mal georeferenciadas
limites <- getbb("Chapinero, Bogotá, Colombia")
limites
train_chapinero <- train_aptos %>%
filter(
between(lon, limites[1, "min"], limites[1, "max"]) &
between(lat, limites[2, "min"], limites[2, "max"])
)
leaflet() %>%
addTiles() %>%
addCircles(lng = train_chapinero$lon,
lat = train_chapinero$lat)
library(tidytext)
library(dplyr)
# Tokenización de la columna 'description'
train_chapinero_tokens <- train_chapinero %>%
unnest_tokens(word, description)  # Esto tokeniza por palabra
#Quitar stop words
data("stop_words")
train_chapinero_tokens_clean <- train_chapinero_tokens %>%
anti_join(stop_words)
train_chapinero_tokens_clean %>%
count(word, sort = TRUE)
train_chapinero_tokens_clean %>%
count(property_id, word) %>%
spread(key = word, value = n, fill = 0)
library(dplyr)
# Vector con palabras agrupadas
parking <- c("parqueadero", "garaje")
terrace <- "terraza"
gym <- "gimnasio"
laundry <- "lavanderia"
elevator <- "ascensor"
# Variable dummy para cada caracteristica
dummies_df <- train_chapinero_tokens_clean %>%
mutate(binaria_parking = word %in% parking,
binaria_terrace = word %in% terrace,
binaria_gym = word %in% gym,
binaria_laundry = word %in% laundry,
binaria_elevator = word %in% elevator) %>%
group_by(property_id) %>%
summarise(across(starts_with("binaria_"), ~as.integer(any(.))))
# Unir a df
train_chapinero <- left_join(train_chapinero, dummies_df, by = "property_id")
View(train_chapinero)
knitr::opts_chunk$set(echo = TRUE)
library(pacman)
# Cargar las librerías listadas e instalarlas en caso de ser necesario
p_load(tidyverse, # Manipular dataframes
stringi, # Manipular cadenas de texto
rio, # Importar datos fácilmente
sf, # Leer/escribir/manipular datos espaciales
tidymodels, # entrenamiento de modelos
spatialsample) # Muestreo espacial para modelos de aprendizaje automático
# Importamos datos
db <- import("https://raw.githubusercontent.com/ignaciomsarmiento/datasets/main/house_priceCALI_Clean.rds")
View(db)
test <- db %>% subset( l4 == 'Lili' )
View(test)
train <- db %>% subset( l4 != 'Lili' | is.na(l4)==TRUE )
nrow(test)/nrow(train)
elastic_net_spec <- linear_reg(penalty = tune(), mixture = tune()) %>%
set_engine("glmnet")
library(pacman)
# Cargar las librerías listadas e instalarlas en caso de ser necesario
p_load(tidyverse, # Manipular dataframes
stringi, # Manipular cadenas de texto
rio, # Importar datos fácilmente
sf, # Leer/escribir/manipular datos espaciales
tidymodels, # entrenamiento de modelos
spatialsample,
parsnip) # Muestreo espacial para modelos de aprendizaje automático
elastic_net_spec <- linear_reg(penalty = tune(), mixture = tune()) %>%
set_engine("glmnet")
grid_values <- grid_regular(penalty(range = c(-2,1)), levels = 50) %>%
expand_grid(mixture = c(0, 0.25,  0.5, 0.75,  1))
library(tidymodels)
library(dials)
grid_values <- grid_regular(penalty(range = c(-2,1)), levels = 50) %>%
expand_grid(mixture = c(0, 0.25,  0.5, 0.75,  1))
# Primera receta
rec_1 <- recipe(price ~ distancia_parque + area_parque + rooms + bathrooms + property_type , data = train) %>%
step_dummy(all_nominal_predictors()) %>%  # crea dummies para las variables categóricas
step_interact(terms = ~ distancia_parque:matches("property_type_") + area_parque:matches("property_type_")) %>%
step_novel(all_nominal_predictors()) %>%   # para las clases no antes vistas en el train.
step_zv(all_predictors()) %>%   #  elimina predictores con varianza cero (constantes)
step_normalize(all_predictors())  # normaliza los predictores.
library(recipes)             # o library(tidymodels)
# Primera receta
rec_1 <- recipe(price ~ distancia_parque + area_parque + rooms + bathrooms + property_type , data = train) %>%
step_dummy(all_nominal_predictors()) %>%  # crea dummies para las variables categóricas
step_interact(terms = ~ distancia_parque:matches("property_type_") + area_parque:matches("property_type_")) %>%
step_novel(all_nominal_predictors()) %>%   # para las clases no antes vistas en el train.
step_zv(all_predictors()) %>%   #  elimina predictores con varianza cero (constantes)
step_normalize(all_predictors())  # normaliza los predictores.
View(rec_1)
rec_1
# Segunda receta
rec_2 <- recipe(price ~  distancia_parque + area_parque + rooms + bathrooms + property_type, data = train) %>%
step_dummy(all_nominal_predictors()) %>%
step_interact(terms = ~ distancia_parque:matches("property_type_")+area_parque:matches("property_type_")) %>%
step_interact(terms = ~ distancia_parque:rooms) %>%
step_interact(terms = ~ distancia_parque:area_parque) %>%
step_poly(distancia_parque, area_parque, degree = 2) %>%
step_novel(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
workflow_1 <- workflow() %>%
# Agregar la receta de preprocesamiento de datos. En este caso la receta 1
add_recipe(rec_1) %>%
# Agregar la especificación del modelo de regresión Elastic Net
add_model(elastic_net_spec)
library(workflows)             # o library(tidymodels)
workflow_1 <- workflow() %>%
# Agregar la receta de preprocesamiento de datos. En este caso la receta 1
add_recipe(rec_1) %>%
# Agregar la especificación del modelo de regresión Elastic Net
add_model(elastic_net_spec)
## Lo mismo con la receta rec_2
workflow_2 <- workflow() %>%
add_recipe(rec_2) %>%
add_model(elastic_net_spec)
# definimos nuestra variable como sf
train_sf <- st_as_sf(
train,
# "coords" is in x/y order -- so longitude goes first!
coords = c("lon", "lat"),
# Set our coordinate reference system to EPSG:4326,
# the standard WGS84 geodetic coordinate reference system
crs = 4326
)
set.seed(86936)
block_folds <- spatial_block_cv(train_sf, v = 5)
block_folds
autoplot(block_folds)
p_load("purrr")
walk(block_folds$splits, function(x) print(autoplot(x)))
set.seed(86936)
tune_res1 <- tune_grid(
workflow_1,         # El flujo de trabajo que contiene: receta y especificación del modelo
resamples = block_folds,  # Folds de validación cruzada espacial
grid = grid_values,        # Grilla de valores de penalización
metrics = metric_set(mae)  # metrica
)
library(tune)                  # o library(tidymodels)
set.seed(86936)
tune_res1 <- tune_grid(
workflow_1,         # El flujo de trabajo que contiene: receta y especificación del modelo
resamples = block_folds,  # Folds de validación cruzada espacial
grid = grid_values,        # Grilla de valores de penalización
metrics = metric_set(mae)  # metrica
)
library(tune)                  # o library(tidymodels)
library(yardstick)             # o library(tidymodels)
set.seed(86936)
tune_res1 <- tune_grid(
workflow_1,         # El flujo de trabajo que contiene: receta y especificación del modelo
resamples = block_folds,  # Folds de validación cruzada espacial
grid = grid_values,        # Grilla de valores de penalización
metrics = metric_set(mae)  # metrica
)
collect_metrics(tune_res1)
set.seed(86936)
tune_res2 <- tune_grid(
workflow_2,         # El flujo de trabajo que contiene: receta y especificación del modelo
resamples = block_folds,  # Folds de validación cruzada
grid = grid_values,        # Grilla de valores de penalización
metrics = metric_set(mae)  # metrica
)
set.seed(86936)
tune_res2 <- tune_grid(
workflow_2,         # El flujo de trabajo que contiene: receta y especificación del modelo
resamples = block_folds,  # Folds de validación cruzada
grid = grid_values,        # Grilla de valores de penalización
metrics = metric_set(mae)  # metrica
)
collect_metrics(tune_res2)
# Utilizar 'select_best' para seleccionar el mejor valor.
best_tune_res1 <- select_best(tune_res1, metric = "mae")
best_tune_res1
# Utilizar 'select_best' para seleccionar el mejor valor.
best_tune_res2<- select_best(tune_res2, metric = "mae")
best_tune_res2
# Finalizar el flujo de trabajo 'workflow' con el mejor valor de parametros
res1_final <- finalize_workflow(workflow_1, best_tune_res1)
# Ajustar el modelo  utilizando los datos de entrenamiento
res2_final <- finalize_workflow(workflow_2, best_tune_res2)
EN_final1_fit <- fit(res1_final, data = train)
EN_final2_fit <- fit(res2_final, data = train)
augment(EN_final1_fit, new_data = test) %>%
mae(truth = price, estimate = .pred)
augment(EN_final2_fit, new_data = test) %>%
mae(truth = price, estimate = .pred)
MAE_1 <- augment(EN_final1_fit, new_data = test) %>%
mae(truth = price, estimate = .pred) %>% select(.estimate) %>% pull()
nMAE1<- MAE_1/mean(db$price)*100 %>% round(.,2)
nMAE1
MAE_2 <- augment(EN_final2_fit, new_data = test) %>%
mae(truth = price, estimate = .pred) %>% select(.estimate) %>% pull()
nMAE2<- MAE_2/mean(db$price)*100 %>% round(.,2)
nMAE2
# Instalar y cargar el paquetes
if (!require("pacman")) install.packages("pacman")
library(pacman)
if (!require("MLmetrics")) install.packages("MLmetrics")
library(MLmetrics)
# Usar pacman para cargar (e instalar si es necesario) los paquetes
p_load(tidyverse,   # Manipulación y visualización de datos
dplyr,       # Manipulación de datos
ggplot2,     # Visualización de datos en gráficas
readr,       # Importación de datos
stargazer,   # Formato para tablas
utils,       # Lctura de archivos y manipulación de datos
skimr,       # Resumen estadístico
caret,       # Creación y validación de modelos predictivos
glmnet,      # Modelos de regresión penalizados (Ridge, Lasso)
xgboost,     # Implementación de Gradient Boosting
rpart,       # Árboles de decisión
rpart.plot,  # Visualización de árboles generados por rpart
pROC,        # Curvas ROC y métricas
Metrics,     # Métricas de evaluación
httr,        # Solicitudes http
rio,         # Facilidad para importar data
plotly,      # Gráficos interactivos
osmdata,     # Obtener información de open street maps
sf,          # Leer/escribir/manipular datos espaciales
leaflet,     # Mapas interactivos
gridExtra,   # Graficar en grid
tmaptools,   # Geocode_OMS()
geosphere   # Calcular distancias geográficas como Haversine
)
# 1. Carga de datos train
## Definir URL del archivo Excel en GitHub
url_excel_train <- "https://raw.githubusercontent.com/GeorgeWton1986/T3_BDML/refs/heads/main/03_Stores/train.csv"
## Descargar el archivo temporalmente
temp_file <- tempfile(fileext = ".csv")
GET(url_excel_train, write_disk(temp_file, overwrite = TRUE))
## Leer el archivo CSV en un dataframe
train_aptos <- read_csv(temp_file)
# 2. Carga de datos test hogares
## Definir URL del archivo Excel en GitHub
url_excel_test <- "https://raw.githubusercontent.com/GeorgeWton1986/T3_BDML/refs/heads/main/03_Stores/test.csv"
## Descargar el archivo temporalmente
temp_file <- tempfile(fileext = ".csv")
GET(url_excel_test, write_disk(temp_file, overwrite = TRUE))
# Leer el archivo CSV en un dataframe
test_aptos <- read_csv(temp_file)
# Nombre de las columnas de la base train_hogares
colnames(train_aptos)
# Seleccion de la columnas id de hogares
train_aptos %>%
select(property_id) %>%
head()
# Resumen de apartamentos de la base train_hogares
skim(train_aptos)
# Tratamiento de missing values
train_miss <- skim(train_aptos) %>%
filter(skim_type == "numeric") %>%
select(skim_variable, n_missing)
nobs_train <- nrow(train_aptos)
# Porcentaje de missing por cada caracteristica
train_aptos_miss<- train_miss %>%
mutate(p_missing= n_missing/nobs_train) %>%
filter(n_missing!= 0) %>%
arrange(-n_missing)
train_aptos_miss
# Visualizar variables con missing values
## Gráfico para surface_total (área total)
graf_ms1 <- ggplot(train_aptos, aes(surface_total)) +
geom_histogram(color = "#000000", fill = "#0099F8") +
geom_vline(xintercept = median(train_aptos$surface_total, na.rm = TRUE), linetype = "dashed", color = "red") +
geom_vline(xintercept = mean(train_aptos$surface_total, na.rm = TRUE), linetype = "dashed", color = "blue") +
ggtitle("GRÁFICA 1 - Área total") +
theme_bw() +
theme(plot.title = element_text(size = 18))
ggsave("../04_Views/GRAFICO1-HISTOGRAMA-AREATOTAL.png", plot = graf_ms1, dpi = 150, width = 8, height = 6)
## Gráfico para surface_covered (área privada)
graf_ms2 <- ggplot(train_aptos, aes(surface_covered)) +
geom_histogram(color = "#000000", fill = "#0099F8") +
geom_vline(xintercept = median(train_aptos$surface_covered, na.rm = TRUE), linetype = "dashed", color = "red") +
geom_vline(xintercept = mean(train_aptos$surface_covered, na.rm = TRUE), linetype = "dashed", color = "blue") +
ggtitle("GRÁFICA 2 - Área privada") +
theme_bw() +
theme(plot.title = element_text(size = 18))
ggsave("../04_Views/GRAFICO2-HISTOGRAMA-AREAPRIVADA.png", plot = graf_ms2, dpi = 150, width = 8, height = 6)
## Gráfico para rooms (habitaciones)
graf_ms3 <- ggplot(train_aptos, aes(rooms)) +
geom_histogram(color = "#000000", fill = "#0099F8") +
geom_vline(xintercept = median(train_aptos$rooms, na.rm = TRUE), linetype = "dashed", color = "red") +
geom_vline(xintercept = mean(train_aptos$rooms, na.rm = TRUE), linetype = "dashed", color = "blue") +
ggtitle("GRÁFICA 3 -Habitaciones") +
theme_bw() +
theme(plot.title = element_text(size = 18))
ggsave("../04_Views/GRAFICO3-HISTOGRAMA-HABITACIONES.png", plot = graf_ms3, dpi = 150, width = 8, height = 6)
## Gráfico para bathrooms (baños)
graf_ms4 <- ggplot(train_aptos, aes(bathrooms)) +
geom_histogram(color = "#000000", fill = "#0099F8") +
geom_vline(xintercept = median(train_aptos$bathrooms, na.rm = TRUE), linetype = "dashed", color = "red") +
geom_vline(xintercept = mean(train_aptos$bathrooms, na.rm = TRUE), linetype = "dashed", color = "blue") +
ggtitle("GRÁFICA 4 - Baños") +
theme_bw() +
theme(plot.title = element_text(size = 18))
ggsave("../04_Views/GRAFICO4-HISTOGRAMA-BAÑOS.png", plot = graf_ms4, dpi = 150, width = 8, height = 6)
# Imputación de variables con la mediana y moda
## 1. Variable surface_total con mediana
mediana_surface_total <- median(train_aptos$surface_total, na.rm = TRUE)
train_aptos <- train_aptos  %>%
mutate(surface_total = ifelse(is.na(surface_total) == TRUE, mediana_surface_total, surface_total))
## 2. Variable surface_covered con mediana
mediana_surface_covered <- median(train_aptos$surface_covered, na.rm = TRUE)
train_aptos <- train_aptos  %>%
mutate(surface_covered = ifelse(is.na(surface_covered) == TRUE, mediana_surface_covered, surface_covered))
## 3.  Variable rooms con la moda
moda_rooms <- train_aptos %>%
filter(!is.na(rooms)) %>%
count(rooms) %>%
arrange(desc(n)) %>%
slice(1) %>%
pull(rooms)
train_aptos <- train_aptos  %>%
mutate(rooms = ifelse(is.na(rooms) == TRUE, moda_rooms, rooms))
## 4.Variable bathrooms con la moda
moda_bathrooms <- train_aptos %>%
filter(!is.na(bathrooms)) %>%
count(bathrooms) %>%
arrange(desc(n)) %>%
slice(1) %>%
pull(bathrooms)
train_aptos <- train_aptos  %>%
mutate(bathrooms = ifelse(is.na(bathrooms) == TRUE, moda_bathrooms, bathrooms))
# Validación de correcta imputación de missing values en variables numéricas
skim(train_aptos)
train_aptos <- as.data.frame(train_aptos)
stargazer(train_aptos, type = "text")
# Calcular el precio por metro cuadrado
train_aptos <- train_aptos %>%
mutate(precio_mt2 = round(price / surface_total, 0))
skim(train_aptos)
# Histograma del precio por metro cuadrado
graf_5 <- ggplot(train_aptos, aes(precio_mt2)) +
geom_histogram(color = "#000000", fill = "#0099F8") +
ggtitle("GRÁFICA 4 - Precio por metro cuadrado (millones)") +
scale_x_continuous(labels = function(x) x / 1e6) +
theme_bw() +
theme(plot.title = element_text(size = 18))
ggsave("../04_Views/GRAFICO5-HISTOGRAMA-PRECIOXMETROCUADRADO.png", plot = graf_5, dpi = 150, width = 8, height = 6)
# Box plot del precio por metro cuadrado
graf_6 <- train_aptos %>%
ggplot(aes(y = precio_mt2)) +
geom_boxplot(fill = "darkblue", alpha = 0.4) +
labs(
title = "Muestra completa",
y = "Precio por metro cuadrado (millones)", x = "") +
scale_y_continuous(labels = function(x) x / 1e6) +
theme_bw()
ggsave("../04_Views/GRAFICO6-BOXPLOT-PRECIOXMETROCUADRADO.png", plot = graf_6, dpi = 150, width = 8, height = 6)
# Ante outliers superiores se aplica la Metodología de percentil 99%
#p1 <- quantile(train_aptos$precio_mt2, probs = 0.01, na.rm = TRUE)
p99 <- quantile(train_aptos$precio_mt2, probs = 0.99, na.rm = TRUE)
train_aptos <- train_aptos %>%
filter(precio_mt2 <= p99)
# Filtrar solo los valores menores o iguales al límite superior
graf_7 <- train_aptos %>%
ggplot(aes(y = precio_mt2)) +
geom_boxplot(fill = "darkblue", alpha = 0.4) +
labs(
title = "Muestra filtrada - P99",
y = "Precio por metro cuadrado (millones)", x = "") +
scale_y_continuous(labels = function(x) x / 1e6) +
theme_bw()
ggsave("../04_Views/GRAFICO6-BOXPLOT-PRECIOXMETROCUADRADO-P99.png", plot = graf_7, dpi = 150, width = 8, height = 6)
# Observamos la primera visualización de la ubicación de los inmubles de la base train_aptos
leaflet() %>%
addTiles() %>%
addCircles(lng = train_aptos$lon,
lat = train_aptos$lat)
limites <- getbb("Chapinero, Bogotá, Colombia")
train_localidades <- train_aptos %>%
filter(
lon < limites[1, "min"] | lon > limites[1, "max"] |
lat < limites[2, "min"] | lat > limites[2, "max"]
)
# Visualizar
leaflet() %>%
addTiles() %>%
addCircles(lng = train_localidades$lon,
lat = train_localidades$lat)
library(tidytext)
library(dplyr)
# Tokenización de la columna 'description'
train_localidades_tokens <- train_localidades %>%
unnest_tokens(word, description)  # Esto tokeniza por palabra
#Quitar stop words
data("stop_words")
train_localidades_tokens_clean <- train_localidades_tokens %>%
anti_join(stop_words)
train_localidades_tokens_clean %>%
count(word, sort = TRUE)
