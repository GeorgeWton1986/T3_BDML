unnest_tokens(word, description)
# Quitar stop words
data("stop_words")
test_aptos_tokens_clean <- test_aptos_tokens %>%
anti_join(stop_words)
test_aptos_tokens_clean %>%
count(word, sort = TRUE)
library(dplyr)
#Vector palabras agrupadas
parking <- c("parqueadero", "garaje", "parqueaderos", "garajes")
terrace <- c("terraza", "balcon")
gym <- "gimnasio"
laundry <- "lavanderia"
elevator <- "ascensor"
#Variable dummy para cada caracteristica
dummies_df_test <- test_aptos_tokens_clean %>%
mutate(binaria_parking = word %in% parking,
binaria_terrace = word %in% terrace,
binaria_gym = word %in% gym,
binaria_laundry = word %in% laundry,
binaria_elevator = word %in% elevator) %>%
group_by(property_id) %>%
summarise(across(starts_with("binaria_"), ~as.integer(any(.))))
# Unir a df
test_aptos <- left_join(test_aptos, dummies_df_test, by = "property_id")
# Variables categóricas a convertir en factor
cols_factor <- c(
'year',
'property_type',
'binaria_parking',
'binaria_terrace',
'binaria_gym',
'binaria_laundry',
'binaria_elevator'
)
# Filtrar y preparar datos
train_factors <- train_localidades %>%
select(
property_id,
price,
year,
property_type,
distancia_cai,
distancia_mall,
distancia_bus,
distancia_avenida,
binaria_parking,
binaria_terrace,
binaria_gym,
binaria_laundry,
binaria_elevator
) %>%
mutate(across(all_of(cols_factor), as.factor)) %>%
as.data.frame()
# Quitar NAs del dataframe preparado
train_factors <- na.omit(train_factors) ## Esta es la base que se usará para el entrenamiento
# Variables predictoras
variables_predictoras <- c(
'year',
'property_type',
'distancia_cai',
'distancia_mall',
'distancia_bus',
'distancia_avenida',
'precio_mt2',
'binaria_parking',
'binaria_terrace',
'binaria_gym',
'binaria_laundry',
'binaria_elevator'
)
# Definir fórmula del modelo
variables <- paste(variables_predictoras, collapse = " + ")
formula_modelo <- as.formula(paste("price ~", variables))
# Control de entrenamiento con out-of-bag (OOB)
fitControl <- trainControl(method = "oob")
# Grid de hiperparámetros
tree_grid <- expand.grid(
mtry = 5,
splitrule = "variance",       # para regresión
min.node.size = c(2, 3, 4)
)
# Entrenar el modelo
model_forest <- train(
formula_modelo,
data = train_factors,
method = "ranger",
trControl = fitControl,
tuneGrid = tree_grid,
num.trees = 500,
importance = "permutation"
)
# Variables categóricas a convertir en factor
cols_factor <- c(
'year',
'property_type',
'binaria_parking',
'binaria_terrace',
'binaria_gym',
'binaria_laundry',
'binaria_elevator'
)
# Filtrar y preparar datos
train_factors <- train_localidades %>%
select(
property_id,
price,
year,
property_type,
distancia_cai,
distancia_mall,
distancia_bus,
distancia_avenida,
binaria_parking,
binaria_terrace,
binaria_gym,
binaria_laundry,
binaria_elevator
) %>%
mutate(across(all_of(cols_factor), as.factor)) %>%
as.data.frame()
# Quitar NAs del dataframe preparado
train_factors <- na.omit(train_factors) ## Esta es la base que se usará para el entrenamiento
# Variables predictoras
variables_predictoras <- c(
'year',
'property_type',
'distancia_cai',
'distancia_mall',
'distancia_bus',
'distancia_avenida',
'binaria_parking',
'binaria_terrace',
'binaria_gym',
'binaria_laundry',
'binaria_elevator'
)
# Definir fórmula del modelo
variables <- paste(variables_predictoras, collapse = " + ")
formula_modelo <- as.formula(paste("price ~", variables))
# Las columnas estén en el mismo formato que en entrenamiento
cols_factor <- c(
'year',
'property_type',
'binaria_parking',
'binaria_terrace',
'binaria_gym',
'binaria_laundry',
'binaria_elevator'
)
# Preprocesamiento test
test <- test_aptos %>%
select(
property_id,
year,
property_type,
distancia_cai,
distancia_mall,
distancia_bus,
distancia_avenida,
binaria_parking,
binaria_terrace,
binaria_gym,
binaria_laundry,
binaria_elevator
) %>%
mutate(across(all_of(cols_factor), as.factor)) %>%
as.data.frame()
# Control de entrenamiento con out-of-bag (OOB)
fitControl <- trainControl(method = "oob")
# Grid de hiperparámetros
tree_grid <- expand.grid(
mtry = 5,
splitrule = "variance",       # para regresión
min.node.size = c(2, 3, 4)
)
# Entrenar el modelo
model_forest <- train(
formula_modelo,
data = train_factors,
method = "ranger",
trControl = fitControl,
tuneGrid = tree_grid,
num.trees = 500,
importance = "permutation"
)
# Resultados del modelo
print(model_forest)
# Importancia de variables
varImp(model_forest)
pred <- predict(model_forest, newdata = test)
test <- test %>% mutate(price = pred) %>% select('property_id', 'price')
# Obtener predicciones
pred <- predict(model_forest, newdata = test)
View(test)
pred <- predict(model_forest, newdata = test)
# Obtener predicciones
pred <- predict(model_forest, newdata = test)
# Variables categóricas a convertir en factor
cols_factor <- c(
'year',
'property_type',
'binaria_parking',
'binaria_terrace',
'binaria_gym',
'binaria_laundry',
'binaria_elevator'
)
# Filtrar y preparar datos
train_factors <- train_localidades %>%
select(
property_id,
price,
year,
property_type,
distancia_cai,
distancia_mall,
distancia_bus,
distancia_avenida,
binaria_parking,
binaria_terrace,
binaria_gym,
binaria_laundry,
binaria_elevator
) %>%
mutate(across(all_of(cols_factor), as.factor)) %>%
as.data.frame()
# Quitar NAs del dataframe preparado
train_factors <- na.omit(train_factors) ## Esta es la base que se usará para el entrenamiento
# Variables predictoras
variables_predictoras <- c(
'year',
'property_type',
'distancia_cai',
'distancia_mall',
'distancia_bus',
'distancia_avenida',
'binaria_parking',
'binaria_terrace',
'binaria_gym',
'binaria_laundry',
'binaria_elevator'
)
# Definir fórmula del modelo
variables <- paste(variables_predictoras, collapse = " + ")
formula_modelo <- as.formula(paste("price ~", variables))
# Las columnas estén en el mismo formato que en entrenamiento
cols_factor <- c(
'year',
'property_type',
'binaria_parking',
'binaria_terrace',
'binaria_gym',
'binaria_laundry',
'binaria_elevator'
)
# Preprocesamiento test
test <- test_aptos %>%
select(
property_id,
year,
property_type,
distancia_cai,
distancia_mall,
distancia_bus,
distancia_avenida,
binaria_parking,
binaria_terrace,
binaria_gym,
binaria_laundry,
binaria_elevator
) %>%
mutate(across(all_of(cols_factor), as.factor)) %>%
as.data.frame()
View(test)
# Control de entrenamiento con out-of-bag (OOB)
fitControl <- trainControl(method = "oob")
# Grid de hiperparámetros
tree_grid <- expand.grid(
mtry = 5,
splitrule = "variance",       # para regresión
min.node.size = c(2, 3, 4)
)
# Entrenar el modelo
model_forest <- train(
formula_modelo,
data = train_factors,
method = "ranger",
trControl = fitControl,
tuneGrid = tree_grid,
num.trees = 500,
importance = "permutation"
)
# Resultados del modelo
print(model_forest)
# Importancia de variables
varImp(model_forest)
# Alinear niveles de factores
for (var in cols_factor) {
levels(test[[var]]) <- levels(train_factors[[var]])
}
# Predicción
pred <- predict(model_forest, newdata = test)
# Resultado final
test <- test %>%
mutate(price = pred) %>%
select(property_id, price)
# Alinear niveles de factores
for (var in cols_factor) {
levels(test[[var]]) <- levels(train_factors[[var]])
}
View(train_factors)
# Variables categóricas a convertir en factor
cols_factor <- c(
'year',
'property_type',
'binaria_parking',
'binaria_terrace',
'binaria_gym',
'binaria_laundry',
'binaria_elevator'
)
# Filtrar y preparar datos
train_factors <- train_localidades %>%
select(
property_id,
price,
year,
property_type,
distancia_cai,
distancia_mall,
distancia_bus,
distancia_avenida,
binaria_parking,
binaria_terrace,
binaria_gym,
binaria_laundry,
binaria_elevator
) %>%
mutate(across(all_of(cols_factor), as.factor)) %>%
as.data.frame()
# Quitar NAs del dataframe preparado
train_factors <- na.omit(train_factors) ## Esta es la base que se usará para el entrenamiento
# Variables predictoras
variables_predictoras <- c(
'year',
'property_type',
'distancia_cai',
'distancia_mall',
'distancia_bus',
'distancia_avenida',
'binaria_parking',
'binaria_terrace',
'binaria_gym',
'binaria_laundry',
'binaria_elevator'
)
# Definir fórmula del modelo
variables <- paste(variables_predictoras, collapse = " + ")
formula_modelo <- as.formula(paste("price ~", variables))
# Las columnas estén en el mismo formato que en entrenamiento
cols_factor <- c(
'year',
'property_type',
'binaria_parking',
'binaria_terrace',
'binaria_gym',
'binaria_laundry',
'binaria_elevator'
)
# Preprocesamiento test
test <- test_aptos %>%
select(
property_id,
year,
property_type,
distancia_cai,
distancia_mall,
distancia_bus,
distancia_avenida,
binaria_parking,
binaria_terrace,
binaria_gym,
binaria_laundry,
binaria_elevator
) %>%
mutate(across(all_of(cols_factor), as.factor)) %>%
as.data.frame()
# Control de entrenamiento con out-of-bag (OOB)
fitControl <- trainControl(method = "oob")
# Grid de hiperparámetros
tree_grid <- expand.grid(
mtry = 5,
splitrule = "variance",       # para regresión
min.node.size = c(2, 3, 4)
)
# Entrenar el modelo
model_forest <- train(
formula_modelo,
data = train_factors,
method = "ranger",
trControl = fitControl,
tuneGrid = tree_grid,
num.trees = 500,
importance = "permutation"
)
# Resultados del modelo
print(model_forest)
# Importancia de variables
varImp(model_forest)
# Alinear niveles de factores
for (var in cols_factor) {
levels(test[[var]]) <- levels(train_factors[[var]])
}
# Predicción
pred <- predict(model_forest, newdata = test)
# Resultado final
pred_RF1 <- test %>%
mutate(price = pred) %>%
select(property_id, price)
View(pred_RF1)
# Descargar archivo
write.csv(pred_RF1,
"C:/../03_Stores/10-04_G4_RANDOM-FOREST1.csv", row.names = FALSE,
quote = FALSE)
# Descargar archivo
write.csv(pred_RF1,
"C:/../03_Stores/18-05_G4_RANDOM-FOREST1.csv", row.names = FALSE,
quote = FALSE)
# Descargar archivo
write.csv(pred_RF1,
"C:/MECA/2025/BIG DATA Y MACHINE LEARNING- Ignasio Sarmiento/Taller3/T3_BDML/03_Stores/18-05_G4_RANDOM-FOREST1.csv", row.names = FALSE,
quote = FALSE)
# Si tienes price real en test
MAE <- mean(abs(test$price_real - pred))
print(MAE)
# Predicciones en entrenamiento
pred_train <- predict(model_forest, newdata = train_factors)
# Calcular MAE en entrenamiento
MAE_train <- mean(abs(train_factors$price - pred_train))
print(MAE_train)
View(pred_RF1)
# 1. Crear los folds espaciales (5 bloques)
set.seed(123)
block_folds_rf <- spatial_block_cv(train_espacial, v = 5)
#1. Eliminar variables innecesarias
train_1_EN <- train_factors %>%
select(-property_id)
#2. Crear la receta del entranamiento
# Cargar explícitamente el paquete recipes
receta_1_EN <- recipe(price ~ ., data = train_1_EN) %>%
step_normalize(distancia_cai, distancia_mall, distancia_bus, distancia_avenida) %>% #normalizar solo predictores numéricos (distancias)
step_dummy(all_nominal_predictors()) %>% ## Convertir variables categóricas a dummies
step_zv(all_predictors()) #Remover predictores con varianza cero
# 1. Crear los folds espaciales (5 bloques)
set.seed(123)
block_folds_rf <- spatial_block_cv(train_espacial, v = 5)
set.seed(123)  # Para reproducibilidad
# 1. Crear bloques espaciales para validación cruzada (5 folds)
block_folds_rf <- spatial_block_cv(
train_espacial,
v = 5,
id = "spatial_cv"   # opcional, para identificar los folds
)
# Instalar y cargar el paquetes
if (!require("pacman")) install.packages("pacman")
library(pacman)
if (!require("MLmetrics")) install.packages("MLmetrics")
library(MLmetrics)
install.packages("recipes")
# Usar pacman para cargar (e instalar si es necesario) los paquetes
p_load(tidyverse,   # Manipulación y visualización de datos
dplyr,       # Manipulación de datos
ggplot2,     # Visualización de datos en gráficas
readr,       # Importación de datos
stargazer,   # Formato para tablas
utils,       # Lctura de archivos y manipulación de datos
skimr,       # Resumen estadístico
caret,       # Creación y validación de modelos predictivos
glmnet,      # Modelos de regresión penalizados (Ridge, Lasso)
xgboost,     # Implementación de Gradient Boosting
rpart,       # Árboles de decisión
rpart.plot,  # Visualización de árboles generados por rpart
pROC,        # Curvas ROC y métricas
Metrics,     # Métricas de evaluación
httr,        # Solicitudes http
rio,         # Facilidad para importar data
plotly,      # Gráficos interactivos
osmdata,     # Obtener información de open street maps
sf,          # Leer/escribir/manipular datos espaciales
leaflet,     # Mapas interactivos
gridExtra,   # Graficar en grid
tmaptools,   # Geocode_OMS()
geosphere,   # Calcular distancias geográficas como Haversine
tidymodels,  # Carga recipes, parsnip, rsample, tune, y otros paquetes relacionados
spatialsample, # Muestreo espacial
vip,
recipes
)
install.packages("recipes")
#1. Eliminar variables innecesarias
train_1_EN <- train_factors %>%
select(-property_id)
#2. Crear la receta del entranamiento
# Cargar explícitamente el paquete recipes
receta_1_EN <- recipe(price ~ ., data = train_1_EN) %>%
step_normalize(distancia_cai, distancia_mall, distancia_bus, distancia_avenida) %>% #normalizar solo predictores numéricos (distancias)
step_dummy(all_nominal_predictors()) %>% ## Convertir variables categóricas a dummies
step_zv(all_predictors()) #Remover predictores con varianza cero
#3. Definir el modelo
modelo_1_EN <- linear_reg(penalty = tune(), mixture = tune()) %>%
set_engine("glmnet")
