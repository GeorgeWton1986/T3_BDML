train_localidades_sf <- st_as_sf(
train_localidades,
coords = c("lon", "lat"),
crs = 3116
)
} else {
train_localidades_sf <- train_localidades
}
#2. Verificar el CRS este correcto
print(st_crs(train_localidades_sf))
ggplot(train_localidades, aes(x = distancia_avenida)) +
geom_histogram(bins = 50, fill = "darkblue", alpha = 0.6) +
labs(x = "Distancia mínima a una avenida principal (m)", y = "Cantidad",
title = "Distribución de la distancia a avenidas principales") +
theme_minimal()
# Guardar gráfico
ggsave("../04_Views/GRAFICO8D-DISTANCIAAVENIDA_RESTO.png", dpi = 150, width = 8, height = 6)
# Nombre de las columnas de la base train_hogares
colnames(test_aptos)
# Seleccion de la columnas id de hogares
test_aptos %>%
select(property_id) %>%
head()
# Resumen de apartamentos de la base train_hogares
skim(test_aptos)
# Imputación de missing values con la media de train_aptos
## 1. Variable surface_total con mediana de train
test_aptos <- test_aptos  %>%
mutate(surface_total = ifelse(is.na(surface_total) == TRUE, mediana_surface_total, surface_total))
## 2. Variable surface_covered con mediana de train
test_aptos <- test_aptos  %>%
mutate(surface_covered = ifelse(is.na(surface_covered) == TRUE, mediana_surface_covered, surface_covered))
## 3.  Variable rooms con la moda de train
test_aptos <- test_aptos  %>%
mutate(rooms = ifelse(is.na(rooms) == TRUE, moda_rooms, rooms))
## 4.Variable bathrooms con moda de train
test_aptos <- test_aptos  %>%
mutate(bathrooms = ifelse(is.na(bathrooms) == TRUE, moda_bathrooms, bathrooms))
# Validación de correcta imputación de missing values en test
skim(test_aptos)
# Asegurarte de que lon y lat sean numéricos
test_aptos <- test_aptos %>%
mutate(lon = as.numeric(lon), lat = as.numeric(lat))
# Obtener límites de Chapinero
limite_test <- getbb("Bogotá, Colombia") #Cambio
# Filtrar SOLO los que están dentro de Chapinero
test_aptos <- test_aptos %>% #Cambio
filter(
between(lon, limite_test[1, "min"], limite_test[1, "max"]) & #Cambio
between(lat, limite_test[2, "min"], limite_test[2, "max"]) #Cambio
)
# Crear objeto sf (opcional, si vas a usarlo como spatial)
test_aptos_sf <- st_as_sf(test_aptos, #Cambio
coords = c("lon", "lat"),
crs = 4326)
# Visualizar en el mapa
leaflet() %>%
addTiles() %>%
addCircles(lng = test_aptos$lon, #Cambio
lat = test_aptos$lat) #Cambio
# Transformar test_chapinero a objeto sf si aún no está
test_aptos_sf <- st_as_sf(test_aptos,
coords = c("lon", "lat"),
crs = 4326)
# Transformar a sistema proyectado colombiano (MAGNA-SIRGAS)
test_aptos_metros <- st_transform(test_aptos_sf, crs = 3116)
# Transformar también los malls si no lo has hecho aún (puedes omitir si ya existe)
mall_sf_bogota_metros <- st_transform(mall_sf_bogota, crs = 3116)
# Calcular matriz de distancias
dist_matrix_mall_test <- st_distance(test_aptos_metros, mall_sf_bogota_metros)
# Calcular la distancia mínima a un mall para cada apartamento en test
dist_min_mall_test <- apply(dist_matrix_mall_test, 1, min)
# Agregar la distancia mínima a la base de datos test_chapinero
test_aptos_metros$distancia_mall <- as.numeric(dist_min_mall_test)
# Agregar también la distancia como columna simple (opcional, para df sin geometría)
test_aptos <- test_aptos %>%
mutate(distancia_mall = dist_min_mall_test)
# Revisar resultados
head(test_aptos)
# Transformar test_chapinero a objeto sf si aún no está
test_aptos_sf <- st_as_sf(test_aptos,
coords = c("lon", "lat"),
crs = 4326)
# Transformar a sistema de coordenadas proyectado (MAGNA-SIRGAS)
test_aptos_metros <- st_transform(test_aptos_sf, crs = 3116)
# Transformar los CAIs a CRS 3116 si no lo hiciste antes
cai_sf_bogota_metros <- st_transform(cai_sf_bogota, crs = 3116)
# Calcular la matriz de distancias
dist_matrix_cai_test <- st_distance(test_aptos_metros, cai_sf_bogota_metros)
# Calcular la distancia mínima al CAI más cercano para cada apartamento
dist_min_cai_test <- apply(dist_matrix_cai_test, 1, min)
# Agregar la distancia mínima como nueva columna
test_aptos_metros$distancia_cai <- as.numeric(dist_min_cai_test)
# Agregar la distancia también al data frame base (sin geometría)
test_aptos <- test_aptos %>%
mutate(distancia_cai = dist_min_cai_test)
# Verificar
head(test_aptos)
# Asegúrate de tener test_chapinero_sf como objeto sf
test_aptos_sf <- st_as_sf(test_aptos,
coords = c("lon", "lat"),
crs = 4326)
# Transformar a sistema de coordenadas proyectado (MAGNA-SIRGAS / Bogotá)
test_aptos_metros <- st_transform(test_aptos_sf, crs = 3116)
# Asegúrate de tener las paradas de bus transformadas a CRS 3116
bus_stop_metros <- st_transform(bus_stop_sf, crs = 3116)
# Calcular la matriz de distancias entre apartamentos y paradas de bus
dist_matrix_bus_test <- st_distance(test_aptos_metros, bus_stop_metros)
# Calcular la distancia mínima a una parada de bus
dist_min_bus_test <- apply(dist_matrix_bus_test, 1, min)
# Agregar la distancia mínima a test_chapinero_metros
test_aptos_metros$distancia_bus <- as.numeric(dist_min_bus_test)
# Agregar la distancia a la versión sin geometría
test_aptos <- test_aptos %>%
mutate(distancia_bus = dist_min_bus_test)
# Verificar
head(test_aptos)
# Asegúrate de que test_chapinero_sf tenga geometría (EPSG:4326)
test_aptos_sf <- st_as_sf(test_aptos,
coords = c("lon", "lat"),
crs = 4326)
# 1. Transformar los datos al sistema de coordenadas proyectado (MAGNA-SIRGAS)
test_aptos_metros <- st_transform(test_aptos_sf, crs = 3116)
# 2. Asegúrate de tener avenidas_metros definido previamente
# (Ya creado en tu código anterior como st_transform(avenidas_sf, crs = 3116))
# 3. Calcular la matriz de distancias entre apartamentos y avenidas principales
dist_matrix_avenidas_test <- st_distance(test_aptos_metros, avenidas_metros)
# 4. Calcular la distancia mínima a una avenida
dist_min_avenida_test <- apply(dist_matrix_avenidas_test, 1, min)
# 5. Agregar la distancia mínima a test_chapinero_metros
test_aptos_metros$distancia_avenida <- as.numeric(dist_min_avenida_test)
# 6. Agregar también a la base de datos test_chapinero sin geometría
test_aptos <- test_aptos %>%
mutate(distancia_avenida = dist_min_avenida_test)
# 7. Verificar resultados
head(test_aptos)
library(tidytext)
library(dplyr)
# Tokenización de la columna 'description'
test_aptos_tokens <- test_aptos %>%
unnest_tokens(word, description)
# Quitar stop words
data("stop_words")
test_aptos_tokens_clean <- test_aptos_tokens %>%
anti_join(stop_words)
test_aptos_tokens_clean %>%
count(word, sort = TRUE)
library(dplyr)
#Vector palabras agrupadas
parking <- c("parqueadero", "garaje", "parqueaderos", "garajes")
terrace <- c("terraza", "balcon")
gym <- "gimnasio"
laundry <- "lavanderia"
elevator <- "ascensor"
#Variable dummy para cada caracteristica
dummies_df_test <- test_aptos_tokens_clean %>%
mutate(binaria_parking = word %in% parking,
binaria_terrace = word %in% terrace,
binaria_gym = word %in% gym,
binaria_laundry = word %in% laundry,
binaria_elevator = word %in% elevator) %>%
group_by(property_id) %>%
summarise(across(starts_with("binaria_"), ~as.integer(any(.))))
# Unir a df
test_aptos <- left_join(test_aptos, dummies_df_test, by = "property_id")
# Variables categóricas a convertir en factor
cols_factor <- c(
'year',
'property_type',
'binaria_parking',
'binaria_terrace',
'binaria_gym',
'binaria_laundry',
'binaria_elevator'
)
# Filtrar y preparar datos
train_factors <- train_localidades %>%
select(
property_id,
price,
year,
property_type,
distancia_cai,
distancia_mall,
distancia_bus,
distancia_avenida,
binaria_parking,
binaria_terrace,
binaria_gym,
binaria_laundry,
binaria_elevator,
lat,
lon
) %>%
mutate(across(all_of(cols_factor), as.factor)) %>%
as.data.frame()
# Quitar NAs del dataframe preparado
train_factors <- na.omit(train_factors) ## Esta es la base que se usará para el entrenamiento
# Variables predictoras
variables_predictoras <- c(
'year',
'property_type',
'distancia_cai',
'distancia_mall',
'distancia_bus',
'distancia_avenida',
'binaria_parking',
'binaria_terrace',
'binaria_gym',
'binaria_laundry',
'binaria_elevator'
)
# Definir fórmula del modelo
variables <- paste(variables_predictoras, collapse = " + ")
formula_modelo <- as.formula(paste("price ~", variables))
# Las columnas estén en el mismo formato que en entrenamiento
cols_factor <- c(
'year',
'property_type',
'binaria_parking',
'binaria_terrace',
'binaria_gym',
'binaria_laundry',
'binaria_elevator'
)
# Preprocesamiento test
test <- test_aptos %>%
select(
property_id,
year,
property_type,
distancia_cai,
distancia_mall,
distancia_bus,
distancia_avenida,
binaria_parking,
binaria_terrace,
binaria_gym,
binaria_laundry,
binaria_elevator,
lat,
lon
) %>%
mutate(across(all_of(cols_factor), as.factor)) %>%
as.data.frame()
modelo_cart <- rpart(
formula = formula_modelo,
data = train_factors,
method = "anova"  # Regresión continua
)
# Visualizar el árbol
rpart.plot(modelo_cart)
# Predecir
test$price <- predict(modelo_cart, newdata = test)
# Seleccionar columnas en orden requerido
pred_CART1 <- test %>%
select(property_id, price)
# Descargar archivo
write.csv(pred_CART1,
"C:/MECA/2025/BIG DATA Y MACHINE LEARNING- Ignasio Sarmiento/Taller3/T3_BDML/03_Stores/20-05_G4_CART1.csv", row.names = FALSE,
quote = FALSE)
View(pred_CART1)
# Predecir sobre entrenamiento
pred_train <- predict(modelo_cart, newdata = train_factors)
# Calcular MAE
mae_train <- mean(abs(train_factors$price - pred_train))
print(paste("MAE en entrenamiento:", round(mae_train, 2)))
# Predecir
pred_test <- predict(modelo_cart, newdata = test)
# Calcular MAE
mae_test <- mean(abs(test$price_real - pred_test))  # reemplaza "price_real" por el nombre correcto si difiere
print(paste("MAE en test:", round(mae_test, 2)))
#1. Eliminar variables innecesarias
train_1_EN <- train_factors %>%
select(-property_id)
#2. Crear la receta del entranamiento
# Cargar explícitamente el paquete recipes
receta_1_EN <- recipe(price ~ ., data = train_1_EN) %>%
step_normalize(distancia_cai, distancia_mall, distancia_bus, distancia_avenida) %>% #normalizar solo predictores numéricos (distancias)
step_dummy(all_nominal_predictors()) %>% ## Convertir variables categóricas a dummies
step_zv(all_predictors()) #Remover predictores con varianza cero
#3. Definir el modelo
modelo_1_EN <- linear_reg(penalty = tune(), mixture = tune()) %>%
set_engine("glmnet")
#4. Especificar los paramatros alpha y lambda EN
#Estamos creando la cuadricula de búsqueda para los hiperparámetros del modelo Elastric Net
#Penalty: lambda que controla la regularización
#Mixture: alpha es el balance entre la regularizacion L1 (Lasso) y L2 (Ridge)
grid_elastic <- grid_regular(
penalty(range = c(-3, 0), trans = log10_trans()),  # Explorando valores desde 0.001 hasta 1 en escala logaritmica
mixture(range = c(0, 1)),                          # Explorar de 0 a 1
levels = c(10, 5)                                  # 10 niveles de penalty, 5 de mixture
)
#5. Crear un workflow (flujo de trabajo)
workflow_1_EN <- workflow() %>%
add_recipe(receta_1_EN) %>%
add_model(modelo_1_EN)
#6. Unir train_factors con train_localidades_sf por medio de property_id
train_espacial <- train_localidades_sf %>%
select(property_id, geometry) %>%
inner_join(train_factors, by = "property_id")
#7. Estimacion de validacion cruzada espacial por bloques
#Este metodo de VC por bloques permite:
#1. Mantener la independencia espacial entre los bloques
#2. Evitar el sobreajuste o estimaciones demasiado optimistas del rendimiento del modelo
library(spatialsample)
set.seed(123)
block_folds_EN <- spatial_block_cv(train_espacial, v = 5)
#8. Verificación visual de los bloques de la valiación cruzada
autoplot(block_folds_EN)
#9. Incluir la libreria purrr
#Vamos a ver el proceso de la validacion cruzada
library(purrr)
walk(block_folds_EN$splits, function(x) print(autoplot(x)))
#10. Entrenamiento del modelo con validacion cruzada espacial
resultados_1_EN <- workflow_1_EN %>%
tune_grid(
resamples = block_folds_EN,
grid = grid_elastic,
metrics = metric_set(mae),
control = control_grid(verbose = TRUE)
)
#11. Ver los resultados del modelo 1
autoplot(resultados_1_EN)
#12. Resultado del modelo 1
collect_metrics(resultados_1_EN)
#13. Mostrar los mejores resultados
show_best(resultados_1_EN, metric = "mae", n = 5)
#14. Seleccionar los mejores hiperparámetros
best_params <- select_best(resultados_1_EN, metric = "mae")
print(best_params)
#15. Finalizar el modelo con los mejores parámetros
#Se realiza la implementación de los mejores parámetros en el workflow
#¡¡¡IMPORTANTE!!!
#La función finalize_workflow() sustituye los placeholders tune() por los valores específicos de best_params.
#Ademas, reemplaza penalty = tune() y mixture = tune() por los valores numéricos que resultaron óptimos según el criterio de MAE.
#Por lo tanto, final_workflow estan todos los parámetros especificados con valores estimados, listo para ser entrenado en el conjunto completo de datos.
final_workflow <- workflow_1_EN %>%
finalize_workflow(best_params)
#16. Entrenar el modelo final con todos los datos
final_model <- fit(final_workflow, data = train_1_EN)
#17. Analizar los coeficientes del modelo
# Ver todos los coeficientes (ordenados por magnitud)
library(broom)
coeficientes <- tidy(final_model) %>%
filter(term != "(Intercept)") %>%
arrange(desc(abs(estimate)))
#18. Ver los coeficientes más importantes
head(coeficientes, 10)
#19. Ver la importancia de las variables
library(vip)
vip(extract_fit_parsnip(final_model), num_features = 20)
#20. Calcular el coeficiente de variación de los precios reales
cv_precios_reales <- sd(train_1_EN$price) / mean(train_1_EN$price) * 100
print(paste("CV de los precios reales (%):", round(cv_precios_reales, 2)))
library(recipes)
library(parsnip)
library(workflows)
library(tune)
library(spatialsample)
library(dplyr)
# 1. Receta de preprocesamiento
receta_CART <- recipe(price ~ ., data = train_1_EN) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors())
# 2. Definir modelo CART con parámetros a tunear
modelo_CART <- decision_tree(
cost_complexity = tune(),
tree_depth = tune(),
min_n = tune()
) %>%
set_engine("rpart") %>%
set_mode("regression")
# 3. Grid de búsqueda para hiperparámetros
grid_CART <- grid_regular(
cost_complexity(range = c(-4, -1), trans = log10_trans()),
tree_depth(range = c(3, 10)),
min_n(range = c(2, 10)),
levels = c(4, 4, 4)
)
# 4. Workflow
workflow_CART <- workflow() %>%
add_recipe(receta_CART) %>%
add_model(modelo_CART)
# 5. Validación cruzada espacial con 2 folds
block_folds_CART <- spatial_block_cv(train_espacial, v = 2)
# 6. Búsqueda de hiperparámetros con validación cruzada espacial
resultados_CART <- workflow_CART %>%
tune_grid(
resamples = block_folds_CART,
grid = grid_CART,
metrics = metric_set(mae),
control = control_grid(verbose = TRUE)
)
# 7. Resultados y mejores parámetros
show_best(resultados_CART, metric = "mae", n = 5)
mejores_CART <- select_best(resultados_CART, metric = "mae")
print(mejores_CART)
# 8. Finalizar workflow con mejores parámetros
final_workflow_CART <- finalize_workflow(workflow_CART, mejores_CART)
# 9. Ajustar modelo final con todos los datos de entrenamiento
modelo_final_CART <- fit(final_workflow_CART, data = train_1_EN)
#1. Tomar la base de test y prepararla para la predicción
na_conteo_test <- colSums(is.na(test))
print(na_conteo_test)
test_EN <- test %>%
na.omit()
str(test_EN)
print(dim(test_EN))
#2. Realizar predicciones en el conjunto de prueba
prediccion_EN <- predict(final_model, new_data = test_EN)
resultado_EN_1 <- test_EN %>%
select(property_id) %>%
bind_cols(prediccion_EN)%>%
rename(price = .pred)
head(resultado_EN_1)
#3. Ver la distribución de las predicciones
ggplot(prediccion_EN, aes(x = .pred/1000000)) +  # Convertir a millones
geom_histogram(bins = 30, fill = "skyblue", color = "darkblue") +
labs(title = "Distribución de las predicciones de precio",
x = "Precio predicho (Millones de Pesos)",
y = "Frecuencia") +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),  # Centrar título
axis.text.x = element_text(size = 9)
) +
scale_x_continuous(
labels = scales::comma_format(accuracy = 0.1),  # Formato de números con comas y 1 decimal
breaks = scales::pretty_breaks(n = 8)           # Número adecuado de marcas
)
#4. Calcular estadísticas básicas de las predicciones
summary(prediccion_EN$.pred)
#5. Calcular el coeficiente de variación de las predicciones
cv_predicciones <- sd(prediccion_EN$.pred) / mean(prediccion_EN$.pred) * 100
print(paste("Coeficiente de variación de las predicciones (%):", round(cv_predicciones, 2)))
#6. Unir predicciones con otras variables
analisis_segmentos <- test_EN %>%
select(property_type) %>%
bind_cols(prediccion_EN) %>%
group_by(property_type) %>%
summarize(
media = mean(.pred),
cv = (sd(.pred) / mean(.pred)) * 100
)
print(analisis_segmentos)
#7. Identificar posibles valores atípicos
umbral_superior <- quantile(prediccion_EN$.pred, 0.975)
umbral_inferior <- quantile(prediccion_EN$.pred, 0.025)
outliers <- prediccion_EN %>%
filter(.pred > umbral_superior | .pred < umbral_inferior)
print(paste("Número de outliers en predicciones:", nrow(outliers)))
# Realizar predicciones con el modelo final
predicciones_CART <- predict(modelo_final_CART, new_data = test_EN)
# Combinar property_id con las predicciones
resultado_CART <- test_EN %>%
select(property_id) %>%
bind_cols(predicciones_CART) %>%
rename(price = .pred)
head(resultado_CART)
# Realizar predicciones con el modelo final
predicciones_CART <- predict(modelo_final_CART, new_data = test_EN)
# Combinar property_id con las predicciones
pred_CART2 <- test_EN %>%
select(property_id) %>%
bind_cols(predicciones_CART) %>%
rename(price = .pred)
head(resultado_CART)
write.csv(pred_CART2,
"C:/MECA/2025/BIG DATA Y MACHINE LEARNING- Ignasio Sarmiento/Taller3/T3_BDML/03_Stores/20-05_G4_CART1.csv", row.names = FALSE,
quote = FALSE)
View(train_1_EN)
View(mejores_CART)
# 7. Resultados y mejores parámetros
show_best(resultados_CART, metric = "mae", n = 5)
# Predicciones en entrenamiento
pred_train <- predict(model_forest, newdata = train_factors)
# Predecir
pred_test <- predict(modelo_cart, newdata = test)
# Calcular MAE
mae_test <- mean(abs(test$price_real - pred_test))  # reemplaza "price_real" por el nombre correcto si difiere
print(paste("MAE en test:", round(mae_test, 2)))
# Predecir
pred_test <- predict(modelo_cart, newdata = test)
# Calcular MAE
mae_test <- mean(abs(test$price_real - pred_test))  # reemplaza "price_real" por el nombre correcto si difiere
print(paste("MAE en test:", round(mae_test, 2)))
# Predecir sobre entrenamiento
pred_train <- predict(modelo_cart, newdata = train_factors)
# Calcular MAE
mae_train <- mean(abs(train_factors$price - pred_train))
print(paste("MAE en entrenamiento:", round(mae_train, 2)))
View(train_factors)
# Predecir
pred_test <- predict(modelo_cart, newdata = test)
# Calcular MAE
mae_test <- mean(abs(test$price - pred_test))
print(paste("MAE en test:", round(mae_test, 2)))
View(test)
# Predecir
pred_test <- predict(modelo_cart, newdata = test)
library(rpart)
# Entrenar modelo CART con train_factors y fórmula definida
modelo_cart <- rpart(formula_modelo, data = train_factors)
# Predecir en test (que sí tiene columna price)
pred_test <- predict(modelo_cart, newdata = test)
# Calcular MAE ignorando NAs si hay
mae_test <- mean(abs(test$price - pred_test), na.rm = TRUE)
print(paste("MAE en test:", round(mae_test, 2)))
write.csv(pred_CART2,
"C:/MECA/2025/BIG DATA Y MACHINE LEARNING- Ignasio Sarmiento/Taller3/T3_BDML/03_Stores/21-05_G4_CART2.csv", row.names = FALSE,
quote = FALSE)
